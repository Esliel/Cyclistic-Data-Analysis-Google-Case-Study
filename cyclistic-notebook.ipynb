{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.4.0"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10797600,"sourceType":"datasetVersion","datasetId":6701442}],"dockerImageVersionId":30749,"isInternetEnabled":true,"language":"r","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# load package to import excel files\nlibrary(readxl)\n\n# import first dataset “cyclistic_2019\ncyclistic_2019 <- read_excel(\"/kaggle/input/cyclistic-data-gcc-exercise/cyclistic_2019.xlsx\")\n\n# import first dataset “cyclistic_2020\ncyclistic_2020 <- read_excel(\"/kaggle/input/cyclistic-data-gcc-exercise/cyclistic_2020.xlsx\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:29.746181Z","iopub.execute_input":"2025-02-19T20:07:29.747931Z","iopub.status.idle":"2025-02-19T20:07:45.13392Z","shell.execute_reply":"2025-02-19T20:07:45.131979Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Introduction\n\nThis work is part of the final assignment for the Google Career Certificate for Data Analyst course on the Coursera platform. Data and context were provided by Google Career Certificate. How to process them is a personal assignment.  \n\nThe assignment consists in analyzing data, for the bike-share fictional company \"Cyclistic” in Chicago, as a junior data analyst in the company's marketing team.  \n\nInitial situation : the marketing director wants to change the marketing strategy. She believes that the future success of the company depends on the number of annual subscriptions. Until now, the target audience has been the general public, but she now thinks it's a good idea to focus on occasional users and get them to sign up for an annual subscription. \n\nKey information :  \n\n* 5824 bicycles that are geotracked and locked  \n* 692 stations across Chicago  \n* Bikes can be unlocked from one station and returned to any other station anytime\n* There are two categories of travel pass: casual passes (one journey and one day) and annual season tickets \n* We have two dataframes : one for 2019 and the other for 2020  \n\nQuestions from the client :  \n\n* How do *annual members* (customers who purchase annual memberships) and *casual riders* (customers who purchase single-ride or full-day passes) use Cyclistic bikes differently  \n* Identify trends in service usage  \n* Determine the reasons why *casual riders*  become *annual members*  \n* How can Cyclistic use digital media to influence *casual riders* to become *annual members*\n\n# Setting up my environment\n\n## Imported Datasets\n\n* cyclistic_2019 : about 2019 data  \n* cyclistic_2020 : about 2020 data  \n\nTheses dataframes has already been imported.  \n\n## Loaded Packages\n\nThe readxl package has already been loaded to enable us to import dataframes.  ","metadata":{}},{"cell_type":"code","source":"# Load all the packages we will use in this analysis\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(openxlsx)\nlibrary(lubridate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:45.137573Z","iopub.execute_input":"2025-02-19T20:07:45.139075Z","iopub.status.idle":"2025-02-19T20:07:45.156756Z","shell.execute_reply":"2025-02-19T20:07:45.154905Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data cleaning process\n\nAt the end of each cleaning operation, a check will be performed using tools (such as sum, colnames, summary, str, ...). To simplify this document, we won't always include them in code chuncks.\n\n## Explore dataframes\n\nLet's explore the documents as they were originally given to us, to determine the clean-up actions to come.","metadata":{}},{"cell_type":"code","source":"# Structure of cyclistic_2019\nstr(cyclistic_2019)\n\n# Main statistics of cyclistic_2019\nsummary(cyclistic_2019)\n\n# Structure of cyclistic_2020\nstr(cyclistic_2020)\n\n# Main statistics of cyclistic_2020\nsummary(cyclistic_2020)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:45.159466Z","iopub.execute_input":"2025-02-19T20:07:45.236148Z","iopub.status.idle":"2025-02-19T20:07:45.582573Z","shell.execute_reply":"2025-02-19T20:07:45.580757Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Remarks following observation of these descriptions :  \n\n#### About the structure :  \n\n* the number of columns is different (12 for cyclistic_2019, 13 for cyclistic_2020)  \n* none of the columns have the same name  \n* some columns don't match  \n* the datatype is the right one for each column in each document, but we may need to harmonize it for future merging of these dataframes  \n* both documents are already in wide data format  \n* both documents are already anonymized  \n* comparable number of observations (365,069 for cyclistic_2019, 426,887 for cyclistic_2020)  \n* in both document, there is no column with the hours only, to be able to identify peak activity times\n\n#### About the summary (main statistics) :  \n\n* in cyclistic_2019 some birth years are not consistent (individuals over 100 years old at the time of data collection)  \n* in cyclistic_2019 maximum bike_id (6471) is greater than the number of Cyclistic bikes (5824)  \n\n##### Time data :\n\n* The maximum travel time in cyclistic_2019 is equivalent to around 123 days (10628400 seconds)  \n* The maximum in the end-of-trip column of cyclistic_2019 and in cyclistic_2020 seems inconsistent  \n* For each dataframe, the period covered by the data could be to be from January to March (it would make the data comparable)  \n* In cyclistic_2020 trip duration column is missing  \n\n##### Geographic data :\n\n* The is no column about geographic coordinates in cyclistic_2019 (instead of 4 in cyclistic_2020 about departure and destination latitude and longitude)\n* There is few missing data about geographic coordinates in cyclistic_2020  \n* Both dataframes contain the names of the stations.If they are formatted in the same way (which seems to be), most of the missing geographical data could be found   \n* In both dataframes the maximum in departure and destination station (665 in cyclistic_2019, 675 in cyclistic_2020)is less than the total of the number of station in Cyclistic network (692). This means that all the stations in the network were not used at all during the periods studied  \n\n## Harmonize columns\n\n### Add a year column\n\nTo be able to differentiate the year of the data once the data frames have been merged.  ","metadata":{}},{"cell_type":"code","source":"# Add year in cyclistic_2019 in numeric datatype\ncyclistic_2019 <- cyclistic_2019 %>%\n  mutate(year = as.numeric(\"2019\"))\n\n# Add year in cyclistic_2020 in numeric datatype\ncyclistic_2020 <- cyclistic_2020 %>%\n  mutate(year = as.numeric(\"2020\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:45.585292Z","iopub.execute_input":"2025-02-19T20:07:45.586787Z","iopub.status.idle":"2025-02-19T20:07:45.607799Z","shell.execute_reply":"2025-02-19T20:07:45.605922Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Add trip duration column in cyclistic_2020","metadata":{}},{"cell_type":"code","source":"# Create a trip_duration column in cyclistic_2020 by subtracting the departure date from the arrival date by difftime function\ncyclistic_2020 <- cyclistic_2020 %>%\n  mutate(trip_duration = as.numeric(difftime(ended_at, started_at, units = \"secs\")))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:45.610614Z","iopub.execute_input":"2025-02-19T20:07:45.612133Z","iopub.status.idle":"2025-02-19T20:07:45.629676Z","shell.execute_reply":"2025-02-19T20:07:45.627762Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Add empty missing columns","metadata":{}},{"cell_type":"code","source":"# Add departure_latitude in cyclistic_2019 in numeric datatype\ncyclistic_2019 <- cyclistic_2019 %>%\n  mutate(departure_latitude = as.numeric(NA))\n\n# Add departure_longitude in cyclistic_2019 in numeric datatype\ncyclistic_2019 <- cyclistic_2019 %>%\n  mutate(departure_longitude = as.numeric(NA))\n\n# Add destination_latitude in cyclistic_2019 in numeric datatype\ncyclistic_2019 <- cyclistic_2019 %>%\n  mutate(destination_latitude = as.numeric(NA))\n\n# Add destination_longitude in cyclistic_2019 in numeric datatype\ncyclistic_2019 <- cyclistic_2019 %>%\n  mutate(destination_longitude = as.numeric(NA))\n\n# Add gender in cyclistic_2020 in character datatype\ncyclistic_2020 <- cyclistic_2020 %>%\n  mutate(gender = as.character(NA))\n\n# Add birth_year in cyclistic_2020 in numeric datatype\ncyclistic_2020 <- cyclistic_2020 %>%\n  mutate(birth_year = as.numeric(NA))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:45.632399Z","iopub.execute_input":"2025-02-19T20:07:45.633844Z","iopub.status.idle":"2025-02-19T20:07:45.675745Z","shell.execute_reply":"2025-02-19T20:07:45.673592Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Remove extra columns\n\nA closer look reveals rideable_type in cyclistic_2020 contains only one entry: “docked_bike”. In addition, it wasn't compatible with cyclistic_2019's bike_id column, so we decided to simply delete it.","metadata":{}},{"cell_type":"code","source":"# Remove rideable_type in cyclistic_2020\ncyclistic_2020$rideable_type <- NULL","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:45.67845Z","iopub.execute_input":"2025-02-19T20:07:45.679944Z","iopub.status.idle":"2025-02-19T20:07:45.692768Z","shell.execute_reply":"2025-02-19T20:07:45.690921Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We decide to delete bike_id too in cyclistic_2019. This column contains the identifier of each cyclistic bike, and as we have no other information on these bikes it will be difficult to group them by year of purchase, for example, to find out their condition. As the original data is saved, we'll be able to retrieve it should we ever need it. Without grouping them, there's not much point in identifying the most frequently used bikes.","metadata":{}},{"cell_type":"code","source":"# Remove bikeid in cyclistic_2019\ncyclistic_2019$bikeid <- NULL","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:45.69557Z","iopub.execute_input":"2025-02-19T20:07:45.697051Z","iopub.status.idle":"2025-02-19T20:07:45.709945Z","shell.execute_reply":"2025-02-19T20:07:45.708045Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Harmonize column names","metadata":{}},{"cell_type":"code","source":"# Rename columns in cyclistic_2019\ncyclistic_2019 <- cyclistic_2019 %>%\n  rename(\n    departure_time = start_time,\n    destination_time = end_time,\n    trip_duration = tripduration,\n    departure_station_id = from_station_id,\n    departure_station_name = from_station_name,\n    destination_station_id = to_station_id,\n    destination_station_name = to_station_name,\n    travel_pass = usertype,\n    birth_year = birthyear )\n\n# Rename columns in cyclistic_2020\ncyclistic_2020 <- cyclistic_2020 %>%\n  rename(\n    trip_id = ride_id,\n    departure_time = started_at,\n    destination_time = ended_at,\n    departure_station_id = start_station_id,\n    departure_station_name = start_station_name,\n    destination_station_id = end_station_id,\n    destination_station_name = end_station_name,\n    travel_pass = member_casual,\n    departure_latitude = start_lat,\n    departure_longitude = start_lng,\n    destination_latitude = end_lat,\n    destination_longitude = end_lng )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:45.712788Z","iopub.execute_input":"2025-02-19T20:07:45.71428Z","iopub.status.idle":"2025-02-19T20:07:45.737666Z","shell.execute_reply":"2025-02-19T20:07:45.735743Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Harmonize column data types\n\nTrip ID don't have the same encoding between the two data frame, but as they are unique we can use them in the same column. However, to be able to merge data, we have to use the same datatype.","metadata":{}},{"cell_type":"code","source":"# Convert trip_id in character datatype in cyclistic_2019\ncyclistic_2019 <- cyclistic_2019 %>%\n  mutate(trip_id = as.character(trip_id))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:45.740473Z","iopub.execute_input":"2025-02-19T20:07:45.742027Z","iopub.status.idle":"2025-02-19T20:07:45.757208Z","shell.execute_reply":"2025-02-19T20:07:45.755245Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Basic global cleaning\n\n### Remove excess white spaces\n\nIn each column where the datatype is character, we will remove excess white space before, after and in the middle of the string. \n\nWe're going to use the *trimws* function to remove spaces at the beginning and end, and the *gsub* argument to remove excess spaces in the middle of the string, where we should define what we're removing ( \\\\s+ : when there's a space or more) and what we're replacing it with: (” ”, an empty space), and finally what we're applying it to: ( . : to each column of the dataframe). We'll repeat this operation for each dataframe. ","metadata":{}},{"cell_type":"code","source":"# Remove extra white spaces in cyclistic_2019\ncyclistic_2019 <- cyclistic_2019 %>%\n  mutate_if(is.character,\n    ~trimws(gsub(\"\\\\s+\", \" \", .)))\n\n# Remove extra white spaces in cyclistic_2020\ncyclistic_2020 <- cyclistic_2020 %>%\n  mutate_if(is.character,\n    ~trimws(gsub(\"\\\\s+\", \" \", .)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:45.760137Z","iopub.execute_input":"2025-02-19T20:07:45.761721Z","iopub.status.idle":"2025-02-19T20:07:51.285592Z","shell.execute_reply":"2025-02-19T20:07:51.283651Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Uniform case\n\nWe will use two case styles in this dataset: we will capitalize the beginning of each word for the station name columns (using *stringr::str_to_title*), and we will lowercase the other datatype character columns (using *tolower*). *accross* allows us to apply the function to several columns at once.","metadata":{}},{"cell_type":"code","source":"# Uniform case in cyclistic_2019\ncyclistic_2019 <- cyclistic_2019 %>%\n  mutate(across(\n    where(is.character) & !c(departure_station_name, destination_station_name),\n    tolower)) %>%\n  mutate(across(\n    c(departure_station_name, destination_station_name),\n    stringr::str_to_title))\n\n# Uniform case in cyclistic_2020\ncyclistic_2020 <- cyclistic_2020 %>%\n  mutate(across(\n    where(is.character) & !c(departure_station_name, destination_station_name),\n    tolower)) %>%\n  mutate(across(\n    c(departure_station_name, destination_station_name),\n    stringr::str_to_title))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:51.288498Z","iopub.execute_input":"2025-02-19T20:07:51.29002Z","iopub.status.idle":"2025-02-19T20:07:54.272861Z","shell.execute_reply":"2025-02-19T20:07:54.27092Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Check / remove duplicate","metadata":{}},{"cell_type":"code","source":"# Check for duplicates by trip_id in cyclistic_2019\nsum_dupl_19 <- sum(duplicated(cyclistic_2019$trip_id))\n# Print result\nif(sum_dupl_19 == 0) { \n    print(\"No duplicate in cyclistic_2019, no need to remove them\")\n  } else { \n    print(paste(\"Whoops, \", sum_dupl_19, \"duplicates. We have to remove them !\"))}\n\n# Check for duplicates by trip_id in cyclistic_2020\nsum_dupl_20 <- sum(duplicated(cyclistic_2020$trip_id))\n# Print result\nif(sum_dupl_20 == 0) { \n    print(\"No duplicate in cyclistic_2020, no need to remove them\")\n  } else { \n    print(paste(\"whoops, \", sum_dupl_20, \"duplicates. We have to remove them !\"))}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:54.275749Z","iopub.execute_input":"2025-02-19T20:07:54.277284Z","iopub.status.idle":"2025-02-19T20:07:54.360417Z","shell.execute_reply":"2025-02-19T20:07:54.358656Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Geographic data\n\n### Station name and station ID columns\n\nThere are four columns in our dataset about station names (departure_station_name and destination_station_name in both dataframe) and also four about station ID (departure_station_id and destination_station_id in both dataframe).  \n\nWe'll compare the number of different station names in each column of each dataframe with the number of different ID. If the number is the same (without missing data), we can assume that data in these columns is error-free and ready for use.","metadata":{}},{"cell_type":"code","source":"# Counts the number of unique entries, omitting missing values in each column about name or ID station of our dataset\nl_u_dep_name_19 <- length(unique(na.omit(cyclistic_2019$departure_station_name)))\nl_u_dep_id_19 <- length(unique(na.omit(cyclistic_2019$departure_station_id)))\nl_u_des_name_19 <- length(unique(na.omit(cyclistic_2019$destination_station_name)))\nl_u_des_id_19 <- length(unique(na.omit(cyclistic_2019$destination_station_id)))\nl_u_dep_name_20 <- length(unique(na.omit(cyclistic_2020$departure_station_name)))\nl_u_dep_id_20 <- length(unique(na.omit(cyclistic_2020$departure_station_id)))\nl_u_des_name_20 <- length(unique(na.omit(cyclistic_2020$destination_station_name)))\nl_u_des_id_20 <- length(unique(na.omit(cyclistic_2020$destination_station_id)))\n\n# Length comparison between departure_station_name and departure_station_id ID in cyclistic_2019\nif (l_u_dep_name_19 == l_u_dep_id_19) { \n  print(\"length of departure_station_name and departure_station_id is the same, data is useable (cyclistic_2019)\")\n} else { \n  print(\"Warning, there are some errors: length of departure_station_name and departure_station_id is NOT the same (cyclistic_2019)\")}\n\n# Length comparison between destination_station_name and destination_station_id in cyclistic_2019\nif (l_u_des_name_19 == l_u_des_id_19) { \n  print(\"length of destination_station_name and destinatione_station_id is the same, data is useable (cyclistic_2019)\")\n} else { \n  print(\"Warning, there are some errors: length of destination_station_name and destination_station_id is NOT the same (cyclistic_2019)\")}\n\n# Length comparison between departure_station_name and departure_station_id in cyclistic_2020\nif (l_u_dep_name_20 == l_u_dep_id_20) { \n  print(\"length of departure_station_name and departure_station_id is the same, data is useable (cyclistic_2020)\")\n} else { \n  print(\"Warning, there are some errors: length of departure_station_name and departure_station_id is NOT the same (cyclistic_2020)\")}\n\n# Length comparison between destination_station_name and destination_station_id in cyclistic_2020\nif (l_u_dep_name_20 == l_u_dep_id_20) { \n  print(\"length of destination_station_name and destination_station_id is the same, data is useable (cyclistic_2020)\")\n} else { \n  print(\"Warning, there are some errors: length of destination_station_name and destination_station_id is NOT the same (cyclistic_2020)\")}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:54.36317Z","iopub.execute_input":"2025-02-19T20:07:54.364584Z","iopub.status.idle":"2025-02-19T20:07:54.477202Z","shell.execute_reply":"2025-02-19T20:07:54.475338Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Latitude and longitude\n\ncyclistic_2020 contains the latitude and longitude of each station. We're going to create and complete these same columns for cyclistic_2019. To do this, we first need to create a correspondence table between station names, latitude and longitude. From this table we'll be able to fill in the missing data in each dataframe.  ","metadata":{}},{"cell_type":"code","source":"# Create a correspondence table between station name, latitude and longitude\ncorrespondence_table_station_name_lat_long <- cyclistic_2020 %>%\n  select(station_name = departure_station_name, \n         latitude = departure_latitude, \n         longitude = departure_longitude) %>%\n  bind_rows(\n    cyclistic_2020 %>%\n      select(station_name = destination_station_name, \n             latitude = destination_latitude, \n             longitude = destination_longitude)) %>%\n  drop_na() # Remove rows with missing data\n\n# Checks for each station_name entry, the corresponding latitude and longitude are the same\ncheck_corresponding_lat_long <- correspondence_table_station_name_lat_long %>%\n  group_by(station_name) %>%\n  summarise(n_lat_long = n_distinct(latitude, longitude)) %>%\n  filter(n_lat_long > 1)\n# Print result\nif (nrow(check_corresponding_lat_long) == 0) { print(\"Data is clean, you can remove duplicates.\")\n} else {  print(\"There are some stations with wrong data, we have to fix it\")}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:54.48009Z","iopub.execute_input":"2025-02-19T20:07:54.48162Z","iopub.status.idle":"2025-02-19T20:07:54.719554Z","shell.execute_reply":"2025-02-19T20:07:54.71774Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Keep only one row for each station name (and keep other colomns)\ncorrespondence_table_station_name_lat_long <- correspondence_table_station_name_lat_long %>%\n  distinct(station_name, .keep_all = TRUE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:54.722353Z","iopub.execute_input":"2025-02-19T20:07:54.723888Z","iopub.status.idle":"2025-02-19T20:07:54.751026Z","shell.execute_reply":"2025-02-19T20:07:54.749152Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Our correspondence table between station names, latitude and longitude is complete. Now we will use it to complete missing data in cylistic_2019 (There is just one missing data in theses columns in cyclistic_2020 but we can't fix it because none of these columns have been completed). As the stations used in 2019 and 2020 are a bit different, there will necessarily be some missing data in cyclistic_2019.  ","metadata":{}},{"cell_type":"code","source":"# Complete missing data about departure latitude and longitude in cyclistic_2019\n# Here, left data frame is cyclistic_2019, right dataframe is correspondence_table_station_name_lat_long\n# When doing a left_join, if both dataframes have columns with the same name, R automatically renames them with a .x and a .y at the end of the name\ncyclistic_2019 <- cyclistic_2019 %>%\n  left_join(correspondence_table_station_name_lat_long, \n            by = c(\"departure_station_name\" = \"station_name\")) %>%\n  mutate(\n    departure_latitude = ifelse(is.na(departure_latitude), latitude, departure_latitude),\n    departure_longitude = ifelse(is.na(departure_longitude), longitude, departure_longitude)) %>%\n  select(-latitude, -longitude)  # Remove temporary columns\n\n# Complete missing data about destination latitude and longitude in cyclistic_2019\ncyclistic_2019 <- cyclistic_2019 %>%\n  left_join(correspondence_table_station_name_lat_long, \n            by = c(\"destination_station_name\" = \"station_name\")) %>%\n  mutate(\n    destination_latitude = ifelse(is.na(destination_latitude), latitude, destination_latitude),\n    destination_longitude = ifelse(is.na(destination_longitude), longitude, destination_longitude)) %>%\n  select(-latitude, -longitude)  # Remove temporary columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:54.753869Z","iopub.execute_input":"2025-02-19T20:07:54.755311Z","iopub.status.idle":"2025-02-19T20:07:55.172159Z","shell.execute_reply":"2025-02-19T20:07:55.170273Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Time data\n\n### Trip duration\n\nAs a reminder, both dataframes appear to cover the period from January to March. However, in both, we noticed the presence of some anomalous data. We're going to check the validity of our data by deleting all data longer than 24h (96400 seconds).","metadata":{}},{"cell_type":"code","source":"# Delete trip duration longer than 24h (86400 seconds) in cyclistic_2019\ncyclistic_2019 <- cyclistic_2019 %>%\n  filter(trip_duration <= 86400)\n\n# Discover the date of the last bike return in cyclistic_2019\nmax(cyclistic_2019$destination_time)\n\n# Delete trip duration longer than 24h (86400 seconds) in cyclistic_2020\ncyclistic_2020 <- cyclistic_2020 %>%\n  filter(trip_duration <= 86400)\n\n# Discover the date of the last bike return in cyclistic_2020\nmax(cyclistic_2020$destination_time)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:55.174904Z","iopub.execute_input":"2025-02-19T20:07:55.176344Z","iopub.status.idle":"2025-02-19T20:07:55.345188Z","shell.execute_reply":"2025-02-19T20:07:55.343281Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In both dataframes, the return date of the last bike in our data is April 1, so the data is usable.\n\n### Create a time column and a date column\n\nTo be able to identify days and peak times independently, we'll create new columns. ","metadata":{}},{"cell_type":"code","source":"# Create a column with only hour then a column with only the day of week for departure_time in cyclistic_2019\ncyclistic_2019 <- cyclistic_2019 %>%\n  mutate(\n    departure_hour = hour(departure_time),\n    departure_day_of_week = as.character(wday(departure_time, label = TRUE, abbr = FALSE)))\n\n# Create a column with only hour then a column with only the day of week for destination_time in cyclistic_2019\ncyclistic_2019 <- cyclistic_2019 %>%\n  mutate(\n    destination_hour = hour(destination_time),\n    destination_day_of_week = as.character(wday(destination_time, label = TRUE, abbr = FALSE)))\n\n# Create a column with only hour then a column with only the day of week for departure_time in cyclistic_2020\ncyclistic_2020 <- cyclistic_2020 %>%\n  mutate(\n    departure_hour = hour(departure_time),\n    departure_day_of_week = as.character(wday(departure_time, label = TRUE, abbr = FALSE)))\n\n# Create a column with only hour then a column with only the day of week for destination_time in cyclistic_2020\ncyclistic_2020 <- cyclistic_2020 %>%\n  mutate(\n    destination_hour = hour(destination_time),\n    destination_day_of_week = as.character(wday(destination_time, label = TRUE, abbr = FALSE)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:55.347972Z","iopub.execute_input":"2025-02-19T20:07:55.349414Z","iopub.status.idle":"2025-02-19T20:07:57.628633Z","shell.execute_reply":"2025-02-19T20:07:57.626697Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## User & Bike Data  \n\n### Travel pass columns\n\nFor each row, this column is used to identify if the travel pass held by the cyclist is a temporary pass (one trip or one day) or if the cyclist has used an annual pass. We will use “member” to refer to the annual pass, \"casual\" to refer to an occasional pass.","metadata":{}},{"cell_type":"code","source":"# Turns all “subscriber” into “member” and all “customer” into “casual” in cyclistic_2019\ncyclistic_2019 <- cyclistic_2019 %>%\n  mutate(travel_pass = case_when(\n    travel_pass == \"subscriber\" ~ \"member\",\n    travel_pass == \"customer\" ~ \"casual\"))\n\n# Checks for errors in cyclistic_2019\nunique(cyclistic_2019$travel_pass)\n\n# Checks for errors in cyclistic_2020\nunique(cyclistic_2020$travel_pass)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:57.633055Z","iopub.execute_input":"2025-02-19T20:07:57.634979Z","iopub.status.idle":"2025-02-19T20:07:57.703784Z","shell.execute_reply":"2025-02-19T20:07:57.701885Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Birth year columns\n\nIn cyclistic_2019 only, there is a birth year column. Some data are unexpected: the minimum year is 1900, which would make a user over 100 years old. ","metadata":{}},{"cell_type":"code","source":"# Turn birth years in or before 1900 in NA\ncyclistic_2019 <- cyclistic_2019 %>%\n  mutate(birth_year = ifelse(birth_year < 1919, NA, birth_year))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:57.706406Z","iopub.execute_input":"2025-02-19T20:07:57.707971Z","iopub.status.idle":"2025-02-19T20:07:57.731704Z","shell.execute_reply":"2025-02-19T20:07:57.729815Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Merging dataframes","metadata":{}},{"cell_type":"code","source":"# Merging cyclistic_2019 and cyclistic_2020\ncyclistic_ready_for_analysis <- bind_rows(cyclistic_2019, cyclistic_2020)\n\n#Structure of our new dataframe\nstr(cyclistic_ready_for_analysis)\n\n# Main statistics of our new dataframe\nsummary(cyclistic_ready_for_analysis)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:57.734399Z","iopub.execute_input":"2025-02-19T20:07:57.735859Z","iopub.status.idle":"2025-02-19T20:07:58.432457Z","shell.execute_reply":"2025-02-19T20:07:58.430716Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now that our data is clean, we can move on to analyzing it.\n\n# Data analysis\n\n## Member vs casual\n\nFirst, for information only, we want to know percentage of casual for each year.","metadata":{}},{"cell_type":"code","source":"cyclistic_ready_for_analysis %>%\n  group_by(year) %>%\n  summarise(\n    sum_casual = sum(travel_pass == \"casual\"),\n    sum_member = sum(travel_pass == \"member\"),\n    percentage_casual = round(sum_casual / n() * 100, 2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:58.435127Z","iopub.execute_input":"2025-02-19T20:07:58.436558Z","iopub.status.idle":"2025-02-19T20:07:58.493118Z","shell.execute_reply":"2025-02-19T20:07:58.491429Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We are seeing an increase in the use of cyclistic, both casual and annual pass. This means that there are probably some riders “casuals” who have been converted to “members” between 2019 and 2020.\n\nWe want to better know members and casuals users profiles.\n\n## Gender\n\nWe know that gender data is only available for 2019, so we'll only be looking at this data.","metadata":{}},{"cell_type":"code","source":"cyclistic_ready_for_analysis %>%\n  \n# Filter data to see 2019 only then group all \"member\" and group all “member” values \n# and group all “casual” values\n  filter(year == 2019) %>%\n  group_by(travel_pass) %>%\n  \n  summarise(\n    sum_male = sum(gender == \"male\", na.rm = TRUE),\n    sum_female = sum(gender == \"female\", na.rm = TRUE),\n    sum_na = sum(is.na(gender))) %>%\n  \n# Calculate the percentages: of women to men, of men to women (excluding missing data). \n# Then calculate the percentage of missing data in relation to the gendered data recorded.\n  mutate(\n    percentage_female_no_na = round((sum_female / (sum_male + sum_female)) * 100, 2)) %>%\n   mutate(\n    percentage_male_no_na = round((sum_male / (sum_male + sum_female)) * 100, 2)) %>%\n   mutate(\n    percentage_na = round((sum_na / (sum_na + sum_male + sum_female)) * 100, 2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:58.495797Z","iopub.execute_input":"2025-02-19T20:07:58.497295Z","iopub.status.idle":"2025-02-19T20:07:58.648556Z","shell.execute_reply":"2025-02-19T20:07:58.646671Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"For more than 74% of trips involving an occasional ticket, the gender of the rider is not known, so we will not consider these statistics.  \n\nFor over 99% of members, the gender of the rider is known, and we observe that more trips are made by men (81%) than by women (19%). \n \n## Birth year\n\nWe know that birth year data is only available for 2019, so we'll only be looking at this data.","metadata":{}},{"cell_type":"code","source":"# How many missing values in birth_year column for 2019 data\ncyclistic_ready_for_analysis %>%\n  filter(year == 2019) %>%\n  summarise(\n    sum_na = sum(is.na(birth_year)),\n    total_rows = n()) %>%\n  mutate(\n    percentage_na = round((sum_na / total_rows) * 100, 2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:58.651207Z","iopub.execute_input":"2025-02-19T20:07:58.652671Z","iopub.status.idle":"2025-02-19T20:07:58.724244Z","shell.execute_reply":"2025-02-19T20:07:58.722424Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a histogram showing the distribution of recorded birth\nggplot(cyclistic_ready_for_analysis %>% \n         filter(!is.na(birth_year)), \n       aes(x = birth_year)) + \n  geom_histogram(binwidth = 1, fill = \"steelblue\", color = \"black\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:58.726977Z","iopub.execute_input":"2025-02-19T20:07:58.72847Z","iopub.status.idle":"2025-02-19T20:07:59.465428Z","shell.execute_reply":"2025-02-19T20:07:59.46343Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Few users born after 1995. There's a peak around the 90s and then a gradual decline.\n\n## Trip duration","metadata":{}},{"cell_type":"code","source":"# Mean of trip duration in seconds converted in minutes\nM_trip_duration_min <- mean(cyclistic_ready_for_analysis$trip_duration) / 60\n# Standard deviation in seconds\nET_trip_duration_min <- sd(cyclistic_ready_for_analysis$trip_duration) / 60\n\n# Print mean of trip duration un minutes\nprint(paste(\"Mean of trip duration :\", round(M_trip_duration_min, 0), \"minutes\"))\n\n# Print standard deviation in minutes\nprint(paste(\"Standard deviation of journey time :\", round(ET_trip_duration_min, 0), \"minutes\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:59.468179Z","iopub.execute_input":"2025-02-19T20:07:59.469802Z","iopub.status.idle":"2025-02-19T20:07:59.499633Z","shell.execute_reply":"2025-02-19T20:07:59.497789Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Mean and standard deviation by type of travel pass (member vs casual)\ncyclistic_ready_for_analysis %>%\n  group_by(travel_pass) %>%\n  summarise(\n    M_trip_duration_min_by_pass = mean(trip_duration) / 60,\n    ET_trip_duration_min_by_pass = sd(trip_duration) / 60) %>%\n  mutate(\n    M_trip_duration_min_by_pass = round(M_trip_duration_min_by_pass, 0),\n    ET_trip_duration_min_by_pass = round(ET_trip_duration_min_by_pass, 0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:59.502355Z","iopub.execute_input":"2025-02-19T20:07:59.503808Z","iopub.status.idle":"2025-02-19T20:07:59.558386Z","shell.execute_reply":"2025-02-19T20:07:59.556594Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"For both types of pass, the standard deviation is much higher than the average trip duration. However, we observe that trips using a temporary pass (casual) are longer (36 minutes on average, standard deviation: 75 minutes) than trips using a member pass (11 minutes on average, standard deviation: 21 minutes).","metadata":{}},{"cell_type":"code","source":"# Mean and standard deviation for members, by gender (men vs women)\ncyclistic_ready_for_analysis %>%\n  filter(travel_pass == \"member\") %>%\n  group_by(gender) %>%\n  summarise(\n    M_trip_duration_min_by_pass = mean(trip_duration) / 60,\n    ET_trip_duration_min_by_pass = sd(trip_duration) / 60) %>%\n  mutate(\n    M_trip_duration_min_by_pass = round(M_trip_duration_min_by_pass, 0),\n    ET_trip_duration_min_by_pass = round(ET_trip_duration_min_by_pass, 0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:59.561117Z","iopub.execute_input":"2025-02-19T20:07:59.562615Z","iopub.status.idle":"2025-02-19T20:07:59.703085Z","shell.execute_reply":"2025-02-19T20:07:59.701152Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"If we look at the differences in average trip duration for members between men and women, we realize that there isn't a big difference. However, we notice the standard deviation is lower for women than for men.\n\n## Days of week\n\nWe know that there are no missing values in the departure_day_of_week and destination_day_of_week columns.\n\nWe checked the statistics were similar for the number of trips per day for departures and arrivals, and then collated the data to see the use by day of the week indifferently from departure or arrival.","metadata":{}},{"cell_type":"code","source":"# Add departure_day_of_week and destination_day_of_week in a unique column\ncyclistic_long <- cyclistic_ready_for_analysis %>%\n  pivot_longer(\n    cols = c(departure_day_of_week, destination_day_of_week),\n    values_to = \"day_of_week\")\n\n# Number of trips per day and by travel pass\ncyclistic_summary <- cyclistic_long %>%\n  group_by(travel_pass, day_of_week) %>%\n  summarise(nb_trip_by_day = n(), .groups = \"keep\") %>%\n  \n# percentage of trips by day compared to total trips\n  group_by(travel_pass) %>%\n  mutate(\n    total_trips_all_days = sum(nb_trip_by_day),\n    percentage_trip_by_day = round((nb_trip_by_day / total_trips_all_days) * 100, 1))\n\n# Print result\ncyclistic_summary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:07:59.705935Z","iopub.execute_input":"2025-02-19T20:07:59.707433Z","iopub.status.idle":"2025-02-19T20:08:00.031616Z","shell.execute_reply":"2025-02-19T20:08:00.029884Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print easy read result\nggplot(data = cyclistic_summary %>% filter(!is.na(day_of_week))) +\n  geom_bar(stat = \"identity\", \n           mapping = aes(x = factor(day_of_week, levels = c(\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\")), \n                         y = percentage_trip_by_day, fill = travel_pass)) +\n  facet_wrap(~travel_pass) +\n  theme(axis.text.x = element_text(angle = 45)) +\n  labs(title = \"Percentage of use by day of week and by travel\", \n       x = \"Day of week\", \n       y = \"Percentage of use\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:08:00.034214Z","iopub.execute_input":"2025-02-19T20:08:00.035609Z","iopub.status.idle":"2025-02-19T20:08:00.490287Z","shell.execute_reply":"2025-02-19T20:08:00.48831Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"I've chosen to show the percentage of use for each day of the week compared with the rest of the week, rather than the number of journeys, because the number of journeys done by members is much higher than that done by casuals, making the graph difficult to read. This is a trip distribution, not a trip count.  \n\nWe can see that casuals use Cyclistic more at weekends, while members use it more during the week.\n\n## Hours","metadata":{}},{"cell_type":"code","source":"# Add a column (day_type) to distinct days (week vs week-end) in a temporary dataframe\ncyclistic_ready_for_analysis_temporary <- cyclistic_ready_for_analysis %>%\n  mutate(\n    day_type = ifelse(departure_day_of_week %in% c(\"Saturday\", \"Sunday\"), \"weekend\", \"week\"))\n\n# Merge departure and destination data, duplicates day_type column so that each hour added \n# retains its association with the correct day type\ncyclistic_ready_for_analysis_temporary <- cyclistic_ready_for_analysis_temporary %>%\n  reframe(\n    trip_by_hour = c(departure_hour, destination_hour),\n    day_type = rep(day_type, 2)) %>%\n  group_by(day_type, trip_by_hour) %>%\n  \n# Number of trips for each unique combination of day type and time of day\n  summarise(nb_trip_by_hour = n(), .groups = 'drop') %>%\n  \n# Percentage of trips by hour compared to total by type of day\n  group_by(day_type) %>%\n  mutate(\n    total_trips_by_day = sum(nb_trip_by_hour),\n    percentage = round((nb_trip_by_hour / total_trips_by_day) * 100, 1))\n  \n# Print result\ncyclistic_ready_for_analysis_temporary\n\n# Peak hours in week\nggplot(cyclistic_ready_for_analysis_temporary %>% \n         filter(day_type == \"week\"), \n       aes(x = trip_by_hour, y = nb_trip_by_hour)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Peak hours in week\")\n\n# Peak hours in week-end\nggplot(cyclistic_ready_for_analysis_temporary %>% \n         filter(day_type == \"weekend\"), \n       aes(x = trip_by_hour, y = nb_trip_by_hour)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Peak hours in week-end\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:08:00.493109Z","iopub.execute_input":"2025-02-19T20:08:00.494618Z","iopub.status.idle":"2025-02-19T20:08:01.661993Z","shell.execute_reply":"2025-02-19T20:08:01.660022Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Stations","metadata":{}},{"cell_type":"code","source":"# Combine departure and destination station names\nstation_name_favorites <- cyclistic_ready_for_analysis %>%\n  reframe(\n    station_name_total = c(departure_station_name, destination_station_name)) %>%\n  group_by(station_name_total) %>%\n  \n# Calculate the total number of trips per week: total for each day (departures + arrivals)\n  summarise(nb_trip_by_station = n()) %>%\n  \n# Percentage of each day's trips in relation to total trips\n  mutate(\n    total_trips_by_station = sum(nb_trip_by_station),\n    percentage = round((nb_trip_by_station / total_trips_by_station) * 100, 1)) %>%\n  \n# Sort results by day with most trips (departures + arrivals)\n  arrange(desc(nb_trip_by_station))\n\n# Print result\nhead(station_name_favorites)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T20:08:01.66509Z","iopub.execute_input":"2025-02-19T20:08:01.666792Z","iopub.status.idle":"2025-02-19T20:08:01.792021Z","shell.execute_reply":"2025-02-19T20:08:01.790107Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Unfortunately, we can't give you the names of the stations we've never used, as we don't have a complete list of all cyclistic stations.\n\n### Map\n\nIf you click on the link below this paragraph, you'll be redirected to a web page hosting two interactive Chicago maps (built with Tableau Public) on which you can see how Cyclistic stations are being used. The larger the dot is, the more frequently the station has been used.  The color of the dots also varies: the darker green the dot is, the less the station is used, the redder the dot is, the more it's used. Fly over the dots and you'll see the name of the station concerned, latitude and longitude, and the number of departures from it (noting that departure and arrival data are similar, we have only dealt with departure data here). There are two maps: one for members, the other for casuals.\n\nTableau Public :  \n<https://public.tableau.com/views/Classeur1_17398130870110/Tableaudebord1?:language=fr-FR&:sid=&:redirect=auth&:display_count=n&:origin=viz_share_link>\n\nThe map shows the difference in station use between members and casuals. Stations are much less used by the casuals. However, we note different preferences. This probably reflects the purpose of use: utilitarian vs. recreational. Without knowing Chicago and its points of interest, it's difficult to go deeper into this analysis, but I'm sure it will make sense to people familiar with the city.\n\n# Sharing of findings\n\n## Recommendations\n\n* Promote short daily trips (work, study,...):  \n- Trips by casuals are longer (36 minutes on average, standard deviation: 75 minutes) than trips by members (11 minutes on average, standard deviation: 21 minutes). Perhaps casuals don't think of themselves as subscribers because the daily effort seems too hight, and short trips should be promoted to them.  \n\n* Favorites stations\n- The most frequently used stations are not exactly the same for each type of pass (see interactive map), so it would be interesting to extend the analysis to the places frequented, and imagine targeted communications to initiate the expansion of use to other places and objectives.\n\n* Days and hours of use  \n\nMembers seem to use Cyclistic more on weekdays, while casuals seem to prefer to use it at weekends.\n\nOn weekdays, activity peaks at the beginning and end of the day (8am then 4pm-5pm), while at weekends usage gradually increases, peaking at 2pm and then gradually decreasing again. \n\n* Female audience\n\nIt would be interesting to obtain more data on the gender of casual users, as we can assume that it would be interesting to target more women:  \n- trips completed by “members” are mostly by men (81%) (vs. 19% by women)\n- women seem to use Cyclistic with causal pass (but the data aren't robust enough to really support this finding). \n- If we look at the differences in mean trip duration for members between men and women, we realize that there isn't a big difference in usage, but we do realize that the standard deviation is lower for women than for men. Women seem to prefer shorter trips.\n\n### In conclusion:  \n\n* To target casuals (and even more if you're trying to appeal to a female audience), it's a good idea to promote short weekday trips  \n* Explore Chicago's topography to understand the preference for using some stations more than others (points of interest, transfers, etc). Target communication on stations preferred by casuals to promote different usage (weekday vs. weekend, short vs. long, utilitarian vs. (but also) recreational).  \n\n## Study limits\n\n* The data only covers the period from January to April 1st, as activity can vary considerably from one season to the next  \n* Our main difficulty in this analysis is that the same individual may be represented multiple times in the data, since we only look at trips and do not identify individuals. It is therefore impossible to say how many times the same casual individual occurs  \n* Fictitious data as part of an exercise  \n\n## Story of this data\n\nFollow [this link](https://www.canva.com/design/DAGfirR5GW8/1VdObR50kbUGWXuZODCIHg/edit?utm_content=DAGfirR5GW8&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton) to see a slides presentation of this study\n\n# Used tools\n\n## Data origin\n\nData and exercise from [Data Analytic by Google on Coursera](https://www.coursera.org/professional-certificates/google-data-analytics).\n\n## Analysis and visualization tools\n\nThe programming language used is [R](https://www.r-project.org/)\n\nI used as IDE [RStudio Desktop](https://posit.co/download/rstudio-desktop/).  \n\nI used to build vizualisation with latitude and longitude [Tableau Public](https://public.tableau.com/app/discover). \n\nI used [Canva](https://www.canva.com/) to create the slides presentation\n\n## AI\n\nI used AI as a support tool to gain efficiency (debugging, syntax) and improve my learning by deepening my understanding and exploring new approaches:  \n\n* [DeepSeek](https://www.deepseek.com/)  \n* [ChatGPT](https://openai.com/index/chatgpt/)  \n* [Perplexity Pro](https://www.perplexity.ai/)  \n\n## Translation\n\nI used [DeepL.com (free version)](https://www.deepl.com/fr/translator) to help me translate my content from French to English.  \n","metadata":{}},{"cell_type":"markdown","source":"Thank you for your interest in my work =^-^=","metadata":{}}]}